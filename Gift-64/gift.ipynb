{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.data as Data\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "import numpy as np\n",
    "import gift_64 as gift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(pl.LightningModule):\n",
    "    def __init__(self, \n",
    "                 n_features, \n",
    "                 hidden_size, \n",
    "                 num_layers, \n",
    "                 dropout,\n",
    "                 bidirectional,\n",
    "                 learning_rate,\n",
    "                 criterion):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.n_features = n_features\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.ce = criterion\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=n_features, \n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, \n",
    "                            dropout=dropout,\n",
    "                            bidirectional=bidirectional,\n",
    "                            batch_first=True)\n",
    "        if bidirectional:\n",
    "            self.linear = nn.Sequential(\n",
    "                nn.Linear(hidden_size*2, 1),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        else:\n",
    "            self.linear = nn.Sequential(\n",
    "                nn.Linear(hidden_size, 1),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(len(x), 1, -1)\n",
    "        lstm_out, _ = self.lstm(x.float())\n",
    "        y_pred = self.linear(lstm_out[:,-1])\n",
    "        return y_pred.float()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        y_hat = self(x)\n",
    "        acc_y_hat = y_hat.clone()\n",
    "        loss = self.ce(acc_y_hat.clone().float(), y.clone().float())\n",
    "        acc = torchmetrics.functional.accuracy(acc_y_hat.long(), y.clone().long())\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, sync_dist=True)\n",
    "        self.log('train_acc', acc, on_step=True, on_epoch=True, prog_bar=True, sync_dist=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        acc_y_hat = y_hat.clone()\n",
    "        loss = self.ce(acc_y_hat.clone().float(), y.clone().float())\n",
    "        acc = torchmetrics.functional.accuracy(acc_y_hat.clone().long(), y.clone().long())        \n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True, sync_dist=True)\n",
    "        self.log('val_acc', acc, on_step=True, on_epoch=True, prog_bar=True, sync_dist=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        y_hat = self(x)\n",
    "        loss = self.ce(y_hat.view_as(y), y.float())\n",
    "        acc_y_hat = y_hat.clone()\n",
    "        acc = torchmetrics.functional.accuracy(acc_y_hat.long(), y.clone().long())        \n",
    "        self.log('test_loss', loss)\n",
    "        self.log('test_acc', acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "start_round=1\n",
    "cipher='GIFT_64'\n",
    "num_rounds=4\n",
    "data_train= 2**25 #2**25\n",
    "data_val= 2**22 #2**22\n",
    "difference=(0x0044,0x0000,0x0011,0x0000)\n",
    "pre_trained_model='fresh'\n",
    "if (cipher == \"GIFT_64\"):\n",
    "    wdir = './gift_64_nets/'\n",
    "    # print(difference)\n",
    "    if not os.path.exists(wdir):\n",
    "        os.makedirs(wdir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# X, Y = gift.make_train_data(data_train,\n",
    "#                             num_rounds,\n",
    "#                             diff=difference,\n",
    "#                             r_start=start_round)\n",
    "# X_eval, Y_eval = gift.make_train_data(data_val,\n",
    "#                                         num_rounds,\n",
    "#                                         diff=difference,\n",
    "#                                         r_start=start_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import numpy\n",
    "ver = '2'\n",
    "print(os.getcwd())\n",
    "X = numpy.load(ver + '_X.npy')\n",
    "Y = numpy.load(ver + '_Y.npy')\n",
    "X_eval = numpy.load(ver + '_Xv.npy')\n",
    "Y_eval = numpy.load(ver + '_Yv.npy')\n",
    "\n",
    "X = numpy.reshape(X, (X.shape[0], -1))\n",
    "X_eval = numpy.reshape(X_eval, (X_eval.shape[0], -1))\n",
    "\n",
    "# print(Y.shape)\n",
    "Y = numpy.reshape(Y, (Y.shape[0], 1))\n",
    "# print(Y.shape)\n",
    "Y_eval = numpy.reshape(Y_eval, (Y_eval.shape[0], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# print(type(X))\n",
    "print(X.shape, X.dtype)\n",
    "print(Y)\n",
    "\n",
    "p = dict(\n",
    "    criterion = nn.MSELoss(),\n",
    "#     max_epochs = 10,\n",
    "    n_features = 256*1,\n",
    "    hidden_size = 128*8, # 128,\n",
    "    num_layers = 2,\n",
    "    dropout = 0.2,\n",
    "    learning_rate = 0.001,\n",
    "    bidirectional = True,\n",
    "    # bidirectional = False,\n",
    ")\n",
    "\n",
    "net = LSTM(\n",
    "    n_features = p['n_features'],\n",
    "    hidden_size = p['hidden_size'],\n",
    "    criterion = p['criterion'],\n",
    "    num_layers = p['num_layers'],\n",
    "    dropout = p['dropout'],\n",
    "    bidirectional = p['bidirectional'],\n",
    "    learning_rate = p['learning_rate']\n",
    ")\n",
    "\n",
    "# net = PU(prior1, prior2)\n",
    "\n",
    "train_loader = Data.TensorDataset(*(torch.tensor(X.astype('float32')), torch.tensor(Y.astype('float32'))))\n",
    "#     train_loader = Data.TensorDataset(torch.Tensor(X), torch.Tensor(Y))\n",
    "val_loader = Data.TensorDataset(*(torch.tensor(X_eval.astype('float32')), torch.tensor(Y_eval.astype('float32'))))\n",
    "#     test_loader = Data.TensorDataset(torch.Tensor(X_eval), torch.Tensor(Y_eval))\n",
    "train_loader = DataLoader(train_loader, num_workers=2, batch_size=2**10, pin_memory=True) #, shuffle=True)\n",
    "val_loader = DataLoader(val_loader, num_workers=1, batch_size=2**7, pin_memory=True) #, shuffle=True)\n",
    "del(X, Y, X_eval, Y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pl_bolts.callbacks import PrintTableMetricsCallback\n",
    "from pytorch_lightning.utilities.model_summary import ModelSummary\n",
    "callback = PrintTableMetricsCallback()\n",
    "ModelSummary(net, max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_loader.dataset.tensors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "pl.seed_everything(42, workers=True)\n",
    "bar = pl.callbacks.progress.TQDMProgressBar(refresh_rate=64)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    filename='gift64-{epoch:02d}-{val_acc:.3f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    "    save_last=True,\n",
    "#     every_n_train_steps= 0, every_n_epochs= 1, train_time_interval= None, save_on_train_epoch_end= None\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_acc\",\n",
    "                                    min_delta=0.0000,\n",
    "                                    patience=4, verbose=False, mode=\"max\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "                        auto_lr_find=True,\n",
    "                        callbacks=[bar, checkpoint_callback],\n",
    "                        precision=16,\n",
    "                        gpus=[0],\n",
    "                        deterministic=True,\n",
    "                        max_epochs=201)\n",
    "lr_finder = trainer.tuner.lr_find(net, train_loader, val_loader, max_lr = 0.1 , num_training = 233)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# Results can be found in\n",
    "# print(lr_finder.results)\n",
    "\n",
    "# Plot with\n",
    "fig = lr_finder.plot(suggest=True)\n",
    "fig.show()\n",
    "\n",
    "# Pick point based on plot, or get suggestion\n",
    "new_lr = lr_finder.suggestion()\n",
    "print(new_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.learning_rate = new_lr\n",
    "\n",
    "trainer.fit(net, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# xt, yt = gift.make_train_data(data_val,\n",
    "#                                         num_rounds,\n",
    "#                                         diff=difference,\n",
    "#                                         r_start=start_round)\n",
    "# print(yt)\n",
    "\n",
    "xt = np.load(ver+'_Xt.npy')\n",
    "yt = np.load(ver+'_Yt.npy')\n",
    "\n",
    "xt = numpy.reshape(xt, (xt.shape[0], -1))\n",
    "yt = numpy.reshape(yt, (yt.shape[0], 1))\n",
    "\n",
    "test_loader = Data.TensorDataset(*(torch.tensor(xt.astype('float32')), torch.tensor(yt.astype('float32'))))\n",
    "test_loader = DataLoader(test_loader, num_workers=1, batch_size=2**7, pin_memory=True) #, shuffle=True)\n",
    "\n",
    "# del(xt, yt)\n",
    "ret = trainer.test(net, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ret[0]['test_acc'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
